{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eba6ed8c",
   "metadata": {},
   "source": [
    "# Nome: Gabriel Delgado Panovich de Barros\n",
    "# RA: 176313\n",
    "\n",
    "# Sobre o dataset\n",
    "---\n",
    "> Este arquivo foi copiado diretamente da [fonte](https://www.kaggle.com/datasets/christianlillelund/csgo-round-winner-classification) dos dados, com exceção das imagens.\n",
    "\n",
    "## Context\n",
    "\n",
    "CS:GO is a tactical shooter, where two teams (CT and Terrorist) play for a best of 30 rounds, with each round being 1 minute and 55 seconds. There are 5 players on each team (10 in total) and the first team to reach 16 rounds wins the game. At the start, one team plays as CT and the other as Terrorist. After 15 rounds played, the teams swap side. There are 7 different maps a game can be played on. You win a round as Terrorist by either planting the bomb and making sure it explodes, or by eliminating the other team. You win a round as CT by either eliminating the other team, or by disarming the bomb, should it have been planted.\n",
    "\n",
    "## Content\n",
    "\n",
    "The dataset was originally published by Skybox as part of their CS:GO AI Challenge, running from Spring to Fall 2020. The data set consists of ~700 demos from high level tournament play in 2019 and 2020. Warmup rounds and restarts have been filtered, and for the remaining live rounds a round snapshot have been recorded every 20 seconds until the round is decided. Following the initial publication, It has been pre-processed and flattened to improve readability and make it easier for algorithms to process. The total number of snapshots is 122411.\n",
    "\n",
    "Skybox website: https://skybox.gg/\n",
    "\n",
    "Learn more about CS:GO: https://en.wikipedia.org/wiki/Counter-Strike:_Global_Offensive\n",
    "\n",
    "View CS:GO on Steam Store: https://store.steampowered.com/app/730/CounterStrike_Global_Offensive/\n",
    "\n",
    "Find in-depth information on competitive CS:GO: https://www.hltv.org/\n",
    "\n",
    "## Acknowledgements\n",
    "\n",
    "Thanks to Skybox for taking the time to sample all the snapshots and organising the challenge. It wouldn't be possible to publish any of this without their help.\n",
    "\n",
    "## Inspiration\n",
    "\n",
    "- What types of machine learning models perform best on this dataset?\n",
    "- Which features are most indicative of which teams wins the round?\n",
    "- How often does the team with most money win?\n",
    "- Are some weapons favourable to others?\n",
    "- What attributes should your team have to win? Health, armor or money?\n",
    "\n",
    "## Data Dictionary\n",
    "Note: All snapshots are i.i.d in the sense that they each describe the state of a round\n",
    "and can therefore be treated individually. Although multiple snaphots can be taken from the same round.\n",
    "\n",
    "You are suppose to predict a label (round winner) based on each individual snapshot.\n",
    "\n",
    "|Variable\t     |Definition\t                                        |Key                                      |\n",
    "|----------------|------------------------------------------------------|-----------------------------------------|\n",
    "|time_left       |The time left in the current round.                   |                                         |\n",
    "|ct_score        |The current score of the Counter-Terrorist team.      |                                         |\n",
    "|t_score         |The current score of the Terrorist team.              |                                         |\n",
    "|map             |The map the round is being played on.\t                |E.g. de_dust2, de_inferno and de_overpass|\n",
    "|bomb_planted    |If the bomb has been planted or not.\t                |False = No, True = Yes                   |\n",
    "|ct_health       |The total health of all Counter-Terrorist players.\t|Player health in range 0-100.            |\n",
    "|t_health        |The total health of all Terrorist players.\t        |Player health in range 0-100.            |\n",
    "|ct_armor        |The total armor of all Counter-Terrorist players.\t    |                                         |\n",
    "|t_armor         |The total armor of all Terrorist players.\t            |                                         |\n",
    "|ct_money        |The total bankroll of all Counter-Terrorist players.  |Amount in USD.                           |\n",
    "|t_money         |The total bankroll of all Terrorist players.\t        |Amount in USD.                           |\n",
    "|ct_helmets      |Number of helmets on the Counter-Terrorist team.\t    |                                         |\n",
    "|t_helmets       |Number of helmets on the Terrorist team.\t            |                                         |\n",
    "|ct_defuse_kits  |Number of defuse kits on the Counter-Terrorist team.  |\t                                      |\n",
    "|ct_players_alive|Number of alive players on the Counter-Terrorist team.|Range 0 to 5.                            |\n",
    "|t_players_alive |Number of alive players on the Terrorist team.\t    |Range 0 to 5.                            |\n",
    "|ct_weapon_X     |Weapon X count on Counter-Terrorist team.\t            |E.g. Ak47, Deagle and UMP45.             |\n",
    "|t_weapon_X      |Weapon X count on Terrorist team.\t                    |E.g. Ak47, Deagle and UMP45.             |\n",
    "|ct_grenade_X    |Grenade X count on Counter-Terrorist team.            |E.g. HeGrenade, Flashbang.               |\n",
    "|t_grenade_X     |Grenade X count on Terrorist team.\t                |E.g. HeGrenade, Flashbang.               |\n",
    "|round_winner    |Winner.\t                                            |CT = Counter-Terrorist, T = Terrorist    |\n",
    "\n",
    "# Objetivo do modelo de rede neural\n",
    "---\n",
    "A função desta rede neural é reconhecer padrões nos times (Terroristas ou Contraterroristas) e verificar a influência desses atributos para a vitória da rodada da partida, jogada em uma melhor de 30 rodadas.\n",
    "\n",
    "Utilizamos os dados relativos à quantidade de jogadores vivos em cada time, a vida total dos jogadores de cada time, o dinheiro em USD de cada time, o tempo restante no final do round e se a bomba foi plantada, além do time que venceu a rodada.\n",
    "\n",
    "# Resultados\n",
    "---\n",
    "A análise de cada modelo está no [final do caderno](#resultados-obtidos-resumo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe20f200",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from typing import Dict, Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f480822d",
   "metadata": {},
   "source": [
    "# Preparação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d34eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData(path: str,\n",
    "                shuffle: bool = True,\n",
    "                batch_size: int = 32) -> Tuple[DataLoader, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Recebe o caminho de um dataset e retorna os dados processados e preparados para serem utilizados\n",
    "    no processo de aprendizado do modelo.\n",
    "\n",
    "    ENTRADA:\n",
    "        path: Caminho do arquivo.\n",
    "        batch_size (opcional): Tamanho dos lotes nos dataloaders.\n",
    "    SAÍDA:\n",
    "        Tuple[DataLoader, torch.Tensor]: Tupla que contém os dados normalizados em um DataLoader,\n",
    "        sem labels, e um tensor com as labels do dataset.\n",
    "    \"\"\"\n",
    "    # --- 1. Carregamos o dataset completo, para uma divisão posterior ---\n",
    "    full_data = pd.read_csv(path)\n",
    "\n",
    "    # --- 2. Separação dos features e do label ---\n",
    "    feats_df = full_data.iloc[:, :-1]\n",
    "    label_df = full_data.iloc[:, -1]\n",
    "    # Convertemos em tensores antes de normalizar\n",
    "    feats_tensor = torch.tensor(feats_df.values, dtype=torch.float32)\n",
    "    label_tensor = torch.tensor(label_df.values, dtype=torch.float32)\n",
    "\n",
    "    # --- 3. Etapa de normalização dos dados ---\n",
    "    # Usamos o método de normalização por distribuição\n",
    "    # dim=0 indica que estamos trabalhando com as colunas\n",
    "    mean = feats_tensor.mean(dim=0)\n",
    "    std = feats_tensor.std(dim=0)\n",
    "    # Evita divisão por zero se uma feature for constante\n",
    "    std[std == 0] = 1.0\n",
    "    feats_normalized = (feats_tensor - mean) / std\n",
    "\n",
    "    # --- 4. Criação do TensorDataset e do DataLoader ---\n",
    "    feats_dataset = TensorDataset(feats_normalized)\n",
    "    data_loader = DataLoader(feats_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "    return data_loader, label_tensor\n",
    "\n",
    "def filterData(path: str = 'db/') -> None:\n",
    "    \"\"\"\n",
    "    Função específica para o dataset escolhido. Filtra os dados para manter apenas:\n",
    "\n",
    "    'ct_health',\n",
    "    't_health',\n",
    "    'ct_money',\n",
    "    't_money',\n",
    "    'time_left',\n",
    "    'bomb_planted',\n",
    "    'ct_players_alive',\n",
    "    't_players_alive',\n",
    "    'round_winner'\n",
    "\n",
    "    ENTRADA:\n",
    "        path: Caminho do dataset original, com exceção do arquivo em si.\n",
    "    SAÍDA:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Carrega o arquivo CSV grande.\n",
    "    db_path = os.path.join(path, 'csgo_round_snapshots.csv')\n",
    "    df = pd.read_csv(db_path)\n",
    "\n",
    "    # --- 1. Convertendo a coluna alvo (label) ---\n",
    "    # Mapeia 'CT' para 1 e 'T' para 0\n",
    "    df['round_winner_numeric'] = df['round_winner'].map({'CT': 1, 'T': 0})\n",
    "\n",
    "    # --- 2. Converte a coluna bomb_planted para inteiros ---\n",
    "    # False se torna 0 e True se torna 1\n",
    "    df['bomb_planted'] = df['bomb_planted'].astype(int)\n",
    "\n",
    "    # --- 3. Selecionando e ordenando as colunas finais ---\n",
    "    # Lista com as features selecionadas por você\n",
    "    features = [\n",
    "        'ct_health',\n",
    "        't_health',\n",
    "        'ct_money',\n",
    "        't_money',\n",
    "        'time_left',\n",
    "        'bomb_planted',\n",
    "        'ct_players_alive',\n",
    "        't_players_alive'\n",
    "    ]\n",
    "\n",
    "    # Coluna do label (alvo)\n",
    "    label = 'round_winner_numeric'\n",
    "\n",
    "    # Cria o DataFrame final com as features e o label como a ÚLTIMA coluna\n",
    "    final_df = df[features + [label]]\n",
    "    # Retiramos os dados\n",
    "    filter = final_df[final_df['ct_health'] == 500.0]\n",
    "    filter = filter[filter['t_health'] == 500.0]\n",
    "    final_df.drop(filter.index, inplace=True)\n",
    "\n",
    "    # --- 4. Salvando o novo arquivo CSV ---\n",
    "    output_filename = 'csgo_processed.csv'\n",
    "    final_path = os.path.join(path, output_filename)\n",
    "    final_df.to_csv(final_path, index=False)\n",
    "\n",
    "def viewData(path: str = 'db/') -> pd.DataFrame:\n",
    "    arch = 'csgo_processed.csv'\n",
    "    file_path = os.path.join(path, arch)\n",
    "\n",
    "    df = pd.read_csv(file_path)\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":    \n",
    "    filterData()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2465f1b1",
   "metadata": {},
   "source": [
    "# Funções de plotagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919dd467",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotLosses(loss1: Dict[int, float], loss2: Dict[int ,float], loss1_label: str, loss2_label: str) -> None:\n",
    "    plt.close(\"all\")\n",
    "    plt.figure()\n",
    "    plt.plot(loss1.keys(), loss1.values(), label=loss1_label)\n",
    "    plt.plot(loss2.keys(), loss2.values(), label=loss2_label)\n",
    "    plt.title(f\"{loss1_label} e {loss2_label}\")\n",
    "    plt.xlabel(\"Épocas\")\n",
    "    plt.ylabel(\"Erro\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def hitMap(hit_map, saving: str):\n",
    "    plt.close(\"all\")\n",
    "    plt.figure()\n",
    "    sns.heatmap(hit_map, annot=True, fmt=\"d\", cmap=\"viridis\")\n",
    "    plt.title(\"Hit Map (Frequência dos BMUs)\")\n",
    "    plt.xlabel(\"Coordenada X\")\n",
    "    plt.ylabel(\"Coordenada Y\")\n",
    "    plt.savefig(saving)\n",
    "    plt.show()\n",
    "\n",
    "def uMatrix(u_matrix, saving: str):\n",
    "    plt.close(\"all\")\n",
    "    plt.figure()\n",
    "    # Usar um mapa de cores reverso (ex: \"gray_r\") é comum para U-Matrix\n",
    "    sns.heatmap(u_matrix, cmap=\"gray_r\", annot=False)\n",
    "    plt.title(\"U-Matrix (Fronteiras dos Clusters)\")\n",
    "    plt.xlabel(\"Coordenada X\")\n",
    "    plt.ylabel(\"Coordenada Y\")\n",
    "    plt.savefig(saving)\n",
    "    plt.show()\n",
    "\n",
    "def heatMap(plane_data: Dict[str, np.ndarray], saving) -> None:\n",
    "    \"\"\"\n",
    "    Recebe um dicionário de planos de componentes (heatmaps) e plota\n",
    "    num grid.\n",
    "    \n",
    "    plane_data: Dicionário no formato {nome_da_feature: array_2D_de_pesos}\n",
    "    saving: Caminho para salvar a imagem (ex: \"component_planes.png\")\n",
    "    \"\"\"\n",
    "    plt.close(\"all\")\n",
    "    num_features = len(plane_data)\n",
    "\n",
    "    # --- 1. Determina o layout do grid (ex: 8 features -> 3x3 grid) ---\n",
    "    grid_size = math.ceil(math.sqrt(num_features))\n",
    "    \n",
    "    # --- 2. Cria a figura e os eixos (subplots) ---\n",
    "    fig, axs = plt.subplots(grid_size, grid_size, figsize=(grid_size * 5, grid_size * 5))\n",
    "    # Transforma axs num array 1D para fácil iteração\n",
    "    axs = axs.flatten() \n",
    "\n",
    "    i = 0\n",
    "    # --- 3. Itera sobre o dicionário e plota cada heatmap ---\n",
    "    for feature_name, feature_plane in plane_data.items():\n",
    "        sns.heatmap(feature_plane, ax=axs[i], cmap=\"coolwarm\", cbar=True)\n",
    "        axs[i].set_title(feature_name)\n",
    "        axs[i].set_aspect('equal') # Garante que os \"pixels\" sejam quadrados\n",
    "        i += 1\n",
    "    \n",
    "    # --- 4. Desliga os eixos (subplots) extras que não foram usados ---\n",
    "    for j in range(i, len(axs)):\n",
    "        axs[j].axis('off')\n",
    "\n",
    "    plt.tight_layout() # Ajusta para evitar sobreposição de títulos\n",
    "    plt.savefig(saving)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
